advice_agent_type: "learned_augmented"
expert_path: "assets/checkpoints/ddqn_three_ball_pool/ckpt_policy/model-epoch=18870000-val_reward=0.47.ckpt"
seed: 0
env_type: "Cuesim/ThreeBallHard-Cuelearner"
base_policy: "random"
trainer:
  log_dir: "experiments/2025_02_24_tamer_exploration_policies_narrow"
  max_steps: 10100
  buffer_size: 10100
  start_steps: 0
  update_after: 1000
  update_every: 1000
  grad_steps: -1
  act_noise: 0.0
  eval_steps: 500
  eval_every: 250
  advice_noise: 0.0
  advice_q_threshold: 0.25
  advice_probability: 1.0
  advice_usage_limit: 20000
  adv_update_after: 10
  adv_update_every: 10
  # checkpoints
  policy_checkpoint_options:
    save_best: true
    save_last: true
    save_period: 1000000
  advice_checkpoint_options:
    save_best: false
    save_last: true
    save_period: 50
  verbose: true
  print_every: 250
  advice_scheduler:
    type: linear_fixed_budget
    args:
      budget: 10100
      advice_after: 0
      alpha_init: 1.0
      decay_rate: 0.0
tamer_policy:
  type: "ddqn"
  args:
    batch_size: 100
    hidden_sizes_critic: [400, 400, 300, 300]
    fit_policy: "restarts"
    optimizer: "adam"
    learning_rate: 0.001
    weight_decay: 0.
    gradient_clipping: 0.5
    patience: 100
    discount: 0.

